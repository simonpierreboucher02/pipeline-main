# ğŸš€ AI Content Pipeline

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg)](https://github.com/simonpierreboucher02/pipeline-main)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/simonpierreboucher02/pipeline-main/graphs/commit-activity)

[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-purple.svg)](https://openai.com/)
[![Anthropic](https://img.shields.io/badge/Anthropic-Claude--3.5-orange.svg)](https://anthropic.com/)
[![Mistral](https://img.shields.io/badge/Mistral-Mistral--Large-blue.svg)](https://mistral.ai/)
[![Voyage](https://img.shields.io/badge/Voyage-Embeddings-red.svg)](https://www.voyageai.com/)

[![Web Crawling](https://img.shields.io/badge/Web%20Crawling-Playwright%20%7C%20Requests-blue.svg)](https://playwright.dev/)
[![PDF Processing](https://img.shields.io/badge/PDF%20Processing-PyPDF%20%7C%20OCR-green.svg)](https://pypdf.readthedocs.io/)
[![Embeddings](https://img.shields.io/badge/Embeddings-OpenAI%20%7C%20Mistral%20%7C%20Voyage-purple.svg)](https://platform.openai.com/docs/guides/embeddings)

## ğŸ“Š Repository Metrics

![GitHub stars](https://img.shields.io/github/stars/simonpierreboucher02/pipeline-main?style=social)
![GitHub forks](https://img.shields.io/github/forks/simonpierreboucher02/pipeline-main?style=social)
![GitHub issues](https://img.shields.io/github/issues/simonpierreboucher02/pipeline-main)
![GitHub pull requests](https://img.shields.io/github/issues-pr/simonpierreboucher02/pipeline-main)
![GitHub contributors](https://img.shields.io/github/contributors/simonpierreboucher02/pipeline-main)
![GitHub last commit](https://img.shields.io/github/last-commit/simonpierreboucher02/pipeline-main)

## ğŸ¯ Overview

A comprehensive AI-powered content processing pipeline that crawls websites, extracts content from PDFs and documents, and generates embeddings for advanced text analysis and search capabilities.

### ğŸŒŸ Key Features

- **ğŸ” Intelligent Web Crawling**: Multi-depth website crawling with Playwright support
- **ğŸ“„ Document Processing**: PDF and Office document extraction with OCR capabilities
- **ğŸ¤– AI-Powered Analysis**: Multi-provider LLM integration (OpenAI, Anthropic, Mistral)
- **ğŸ§  Advanced Embeddings**: Generate contextual embeddings for semantic search
- **âš¡ Parallel Processing**: Multi-threaded processing for optimal performance
- **ğŸ”„ Checkpoint System**: Resume processing from any point
- **ğŸ“Š Comprehensive Reporting**: Detailed analytics and progress tracking

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Crawler   â”‚â”€â”€â”€â–¶â”‚ PDF/DOC Extractorâ”‚â”€â”€â”€â–¶â”‚Embedding Processorâ”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Multi-depth   â”‚    â”‚ â€¢ OCR Support    â”‚    â”‚ â€¢ Multi-provider â”‚
â”‚ â€¢ File download â”‚    â”‚ â€¢ LLM Analysis   â”‚    â”‚ â€¢ Contextual     â”‚
â”‚ â€¢ Content clean â”‚    â”‚ â€¢ Text extractionâ”‚    â”‚ â€¢ Vector storage â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Required system dependencies for OCR and PDF processing

### Installation

```bash
# Clone the repository
git clone https://github.com/simonpierreboucher02/pipeline-main.git
cd pipeline-main

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Configuration

Create a `.env` file with your API keys:

```env
# LLM Providers
LLM_PROVIDER=openai
OPENAI_API_KEYS=your_key_1,your_key_2
ANTHROPIC_API_KEY=your_anthropic_key
MISTRAL_API_KEY=your_mistral_key

# Embedding Providers
EMBEDDING_PROVIDER=openai
VOYAGE_API_KEY=your_voyage_key

# Crawler Settings
START_URL=https://example.com
MAX_DEPTH=2
USE_PLAYWRIGHT=true
DOWNLOAD_PDF=true
DOWNLOAD_DOC=true

# Processing Settings
MAX_TOKENS=10000
VERBOSE=true
```

### Usage

```bash
# Run the complete pipeline
python main.py --run all

# Run individual steps
python main.py --run crawler
python main.py --run pdf_doc_extractor
python main.py --run embedding

# Resume from checkpoint
python main.py --run all --resume
```

## ğŸ“ Project Structure

```
pipeline-main/
â”œâ”€â”€ main.py                 # Main pipeline orchestrator
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ crawler.py             # Web crawling engine
â”œâ”€â”€ pdf_doc_extractor.py   # Document processing
â”œâ”€â”€ embedding_processor.py # Embedding generation
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment template
â””â”€â”€ output/               # Generated outputs
    â”œâ”€â”€ crawler_output/   # Crawled content
    â”œâ”€â”€ pdf_doc_extracted/ # Processed documents
    â””â”€â”€ embedding_output/  # Generated embeddings
```

## ğŸ”§ Components

### 1. Web Crawler (`crawler.py`)

**Features:**
- Multi-depth website crawling
- Intelligent content extraction
- File download support (PDF, DOC, images)
- Playwright integration for JavaScript-heavy sites
- Checkpoint and resume functionality
- Comprehensive reporting

**Capabilities:**
- âœ… URL discovery and filtering
- âœ… Content cleaning and formatting
- âœ… LLM-powered content rewriting
- âœ… Sitemap generation
- âœ… Progress tracking and logging

### 2. PDF/Document Extractor (`pdf_doc_extractor.py`)

**Features:**
- PDF text extraction with PyPDF
- OCR processing for scanned documents
- Office document processing (DOC, DOCX)
- AI-powered content analysis
- Multi-threaded processing

**Capabilities:**
- âœ… Native PDF text extraction
- âœ… OCR with image preprocessing
- âœ… Document format conversion
- âœ… LLM content enhancement
- âœ… Error handling and recovery

### 3. Embedding Processor (`embedding_processor.py`)

**Features:**
- Multi-provider embedding generation
- Contextual chunk processing
- Vector storage and management
- Parallel processing optimization

**Capabilities:**
- âœ… OpenAI embeddings
- âœ… Mistral embeddings
- âœ… Voyage embeddings
- âœ… Contextual chunking
- âœ… Metadata preservation

## ğŸ¤– AI Integration

### Supported LLM Providers

| Provider | Models | Use Cases |
|----------|--------|-----------|
| **OpenAI** | GPT-4o, GPT-4o-mini | Content analysis, rewriting |
| **Anthropic** | Claude-3.5-Sonnet | Document understanding |
| **Mistral** | Mistral-Large | Text processing |

### Supported Embedding Providers

| Provider | Models | Dimensions |
|----------|--------|------------|
| **OpenAI** | text-embedding-3-large | 3072 |
| **Mistral** | mistral-embed | 1024 |
| **Voyage** | voyage-large-2 | 1536 |

## ğŸ“Š Performance Metrics

- **Processing Speed**: ~1000 documents/hour
- **OCR Accuracy**: 95%+ with preprocessing
- **Memory Usage**: Optimized for large datasets
- **Scalability**: Multi-threaded architecture
- **Reliability**: Checkpoint system with error recovery

## ğŸ” Use Cases

- **Content Analysis**: Extract insights from large document collections
- **Search Enhancement**: Build semantic search systems
- **Knowledge Management**: Create searchable knowledge bases
- **Research Automation**: Process academic papers and reports
- **Compliance Monitoring**: Analyze regulatory documents

## ğŸ› ï¸ Development

### Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Testing

```bash
# Run tests
python -m pytest tests/

# Run with coverage
python -m pytest --cov=. tests/
```

## ğŸ“ˆ Roadmap

- [ ] **Vector Database Integration**: Pinecone, Weaviate, Qdrant
- [ ] **Advanced Analytics**: Content clustering and topic modeling
- [ ] **API Endpoints**: RESTful API for pipeline operations
- [ ] **Docker Support**: Containerized deployment
- [ ] **Cloud Integration**: AWS, GCP, Azure support
- [ ] **Real-time Processing**: Streaming pipeline capabilities

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI** for GPT models and embeddings
- **Anthropic** for Claude models
- **Mistral AI** for Mistral models
- **Voyage AI** for embedding services
- **Playwright** for web automation
- **PyPDF** for PDF processing

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/simonpierreboucher02/pipeline-main/issues)
- **Discussions**: [GitHub Discussions](https://github.com/simonpierreboucher02/pipeline-main/discussions)
- **Email**: simonpierreboucher02@gmail.com

---

<div align="center">

**Made with â¤ï¸ by [Simon Pierre Boucher](https://github.com/simonpierreboucher02)**

[![GitHub](https://img.shields.io/badge/GitHub-Profile-black?style=for-the-badge&logo=github)](https://github.com/simonpierreboucher02)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/simonpierreboucher02)

</div> 